# Model Configuration
MODEL_API_URL=http://foo/v1/chat/completions
MODEL_API_TOKEN=foo
VLLM_MODEL=mistralai/Mistral-Small-3.2-24B-Instruct-2506 # VLLM Model (for PDF and DOCX processing with images - multimodal)
LLM_MODEL=Qwen/Qwen3-32B # LLM Model (for text-only ZIP, .eml and .xml macro-summaries)
LLM_ENABLE_THINKING=true
USE_VLLM_FOR_ALL=false # Set to true to use VLLM_MODEL for all tasks, ignoring LLM_MODEL

GDRIVE_ENABLED=true
GOOGLE_DRIVE_CREDENTIALS=./secrets/google-credentials.json
GOOGLE_DRIVE_FOLDER_ID=foo # Carpeta raíz de Google Drive (opcional)

API_PORT=8567

UNATTENDED_MODE=true

CHECKPOINT_DIR=/data/checkpoints # Directorio donde se guardan los checkpoints (debe ser accesible desde el contenedor)
CHECKPOINT_INTERVAL=60 # Intervalo en segundos para guardar checkpoints automáticamente
BATCH_SIZE=5           # Procesar 5 archivos por batch (opcional, requiere MAX_WORKERS > 1)
MAX_WORKERS=3          # Usar 3 hilos en paralelo
ARCHIVE_WORKERS=4      # Hilos para procesar archivos dentro de ZIPs/RARs en paralelo
MAX_CONCURRENT_INFERENCE=16 # Máximo de inferencias concurrentes al modelo (semáforo global)

GDRIVE_DOWNLOAD_RETRIES=3

XML_EML_CONTENT_LIMIT=5000

# Límite de palabras para las descripciones generadas por el modelo. Controla la extensión máxima de las descripciones en los prompts
DESCRIPTION_WORD_LIMIT=250

# Comment or keep empty to don't use the VIP-list feature
#NORMALIZE_NAMES='Carlos Charro, Pablo Coca, Luisa Paz, Eva Castaño, Pablo Priesca Balbín'
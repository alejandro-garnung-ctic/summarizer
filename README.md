# Summarizer Microservice

Aplicaci√≥n multimodal dise√±ada para procesar, resumir y mejorar metadatos de documentos (PDFs y ZIPs) usando LLMs avanzados con capacidad de an√°lisis visual.

## üèó Arquitectura

Este microservicio act√∫a como un nodo de procesamiento inteligente en un pipeline de documentos. Est√° dise√±ado para ser **stateless**, **escalable** y **agn√≥stico al entorno**.

### Flujo de Alto Nivel
1.  **Entrada**: Recibe una referencia a un documento (PDF o ZIP) v√≠a API o CLI.
    *   Fuentes soportadas: Google Drive (principal), Sistema de archivos local, Carga directa.
2.  **Procesamiento**:
    *   **PDF**: Extrae visuales clave (primeras/√∫ltimas p√°ginas configurables) y texto. Usa un LLM Multimodal para generar una descripci√≥n sem√°ntica.
    *   **ZIP**: Extrae, procesa individualmente los PDFs contenidos y **genera un macro-resumen sem√°ntico** de toda la colecci√≥n.
3.  **Salida**: Retorna un JSON estructurado con res√∫menes sem√°nticos, listo para indexaci√≥n o actualizaci√≥n de metadatos.

### Diagrama de Componentes
```mermaid
graph TD
    Client[CLI / Web UI / API] -->|Solicitud| Processor[DocumentProcessor]
    
    subgraph "Core Processing"
    Processor -->|PDF / ZIP| VLLM[VLLMService]
    Processor -->|ZIP Macro-Resumen| LLM[LLMService]
    end
    
    VLLM -->|Vision + Context| AI[Multimodal AI - e.g. Mistral]
    LLM -->|Text-only| AI_Text[LLM AI - e.g. Qwen]
    
    subgraph "Storage / Sources"
    Processor -->|Read| GDrive[(Google Drive)]
    Processor -->|Read/Write| Local[(Sistema de Archivos)]
    end
```

√Årbol de directorios:

```bash
alejandro@alejandro-XPS-14-9440:/opt/summarizer$ tree
.
‚îú‚îÄ‚îÄ app
‚îÇ   ‚îú‚îÄ‚îÄ cli.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îú‚îÄ‚îÄ models.py
‚îÇ   ‚îú‚îÄ‚îÄ services
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gdrive.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vllm.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pdf.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ processor.py
‚îÇ   ‚îî‚îÄ‚îÄ templates
‚îÇ       ‚îî‚îÄ‚îÄ index.html
‚îú‚îÄ‚îÄ assets
‚îÇ   ‚îú‚îÄ‚îÄ favicon.png
‚îÇ   ‚îî‚îÄ‚îÄ webui.png
‚îú‚îÄ‚îÄ data
‚îÇ   ‚îî‚îÄ‚îÄ manifest_beetlejuice.json
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ secrets
    ‚îî‚îÄ‚îÄ google-credentials.json
```

## üí° Modos de Operaci√≥n

El servicio soporta diferentes modos de operaci√≥n seg√∫n la fuente de los documentos:

| Modo | Fuente de Entrada | Disponibilidad | Caso de Uso Principal |
| :--- | :--- | :--- | :--- |
| `gdrive` | Google Drive | **API y CLI** | **Producci√≥n**. Procesamiento de carpetas compartidas de Google Drive. Modo principal del servicio. |
| `local` | Sistema de archivos | **CLI** | **Desarrollo/Debug**. Procesamiento de archivos locales desde la l√≠nea de comandos. |
| `upload` | POST Directo | **API** (web) | **Web UI / Pruebas R√°pidas**. Carga manual con controles avanzados (selecci√≥n de p√°ginas, max tokens, exportaci√≥n JSON). |

### üåê Caracter√≠sticas Web UI
- **Control de P√°ginas**: Selecciona p√°ginas iniciales/finales o "Procesar Todo".
- **Exportaci√≥n**: Descarga todos los resultados procesados como un √∫nico archivo JSON.
- **Seguridad**: L√≠mite m√≠nimo de 512 tokens para garantizar JSON v√°lido.
- **Feedback**: Barra de progreso y listado de archivos.

![Web UI](./assets/webui.png)

## üöÄ Inicio R√°pido

### Prerrequisitos
- Docker & Docker Compose
- Credenciales de Google Drive API en `secrets/google-credentials.json` (para modo Google Drive)

1.  **Clonar el repositorio**
2.  **Configurar variables de entorno**
    ```bash
    cp .env.example .env
    ```
    
    Y editar .env con tu configuraci√≥n espec√≠fica.

3.  **Iniciar servicios**
    ```bash
    docker-compose up --build
    ```
    Esto inicia:
    - `summarizer`: El servicio API (e.g. puerto 8567)

4.  **Acceder a las interfaces**
    - **Web UI**: [http://localhost:8567/](http://localhost:8567/) - Arrastra aqu√≠ tus archivos
    - **OpenAPI / Swagger UI**: [http://localhost:8567/docs](http://localhost:8567/docs)

5.  **Verificar conectividad** (opcional)
    ```bash
    # Google Drive
    curl http://localhost:8567/health/gdrive

    # LLM (Texto)
    curl http://localhost:8567/health/llm

    # VLLM (Multimodal)
    curl http://localhost:8567/health/vllm
    ```

> [!IMPORTANT]
> **Shared Drives (Unidades Compartidas)**: Este servicio soporta tanto "Mi unidad" como "Unidades compartidas" de Google Drive. Se debe asegurar de compartir las carpetas con el email de la Service Account (`client_email` en el archivo de credenciales).


## üõ† Uso de la API

### Endpoint Principal: `POST /process-folder`

Procesa todos los archivos PDF y ZIP de una carpeta de Google Drive y retorna un manifest JSON con todos los resultados ordenados.

#### Ejemplo 1: Procesar carpeta por ID con configuraci√≥n por defecto
```bash
curl -X POST "http://localhost:8567/process-folder" \
  -H "Content-Type: application/json" \
  -d '{
    "folder_id": "1C4X9NnTiwFGz3We2D4j-VpINHgCVjV4Y",
    "language": "es"
  }'
```

#### Ejemplo 2: Procesar subcarpetas por nombre (Opcional: ID padre expl√≠cito o desde .env)

```bash
# A: Solo especificando el nombre de la carpeta de inter√©s (se usa la variable de entorno GOOGLE_DRIVE_FOLDER_ID para la carpeta padre)
curl -X POST "http://localhost:8567/process-folder" \
  -H "Content-Type: application/json" \
  -d '{"folder_name": "2005", "language": "es"}'

# Y para redirigir el resultado f√°cilmente (y con par√°metros personalizados):
curl -X POST "http://localhost:8567/process-folder" \
  -H "Content-Type: application/json" \
  -d '{
    "folder_name": "TEST", 
    "language": "es",
    "initial_pages": 2,
    "final_pages": 2,
    "max_tokens": 512
  }' \
  | jq . > summary_TEST.json

# B: Especificando el ID de la carpeta padre expl√≠citamente y el nombre de la carpeta de inter√©s 
curl -X POST "http://localhost:8567/process-folder" \
  -H "Content-Type: application/json" \
  -d '{
    "parent_folder_id": "16JqSg7BuAE_o1wkFM4q4QUWXMgLRcjFh",
    "folder_name": "2005",
    "language": "es"
  }'
```

**Nota**: Los par√°metros `initial_pages` y `final_pages` son opcionales y tienen un valor por defecto de 2 cada uno. Permiten especificar cu√°ntas p√°ginas iniciales y finales de cada PDF se procesar√°n para el an√°lisis.

#### Respuesta t√≠pica

```json
{
  "folder_id": "16JqSg7BuAE_o1wkFM4q4QUWXMgLRcjFh",
  "folder_name": "Beetlejuice",
  "processed_at": "2024-01-15T10:30:00",
  "total_files": 5,
  "results": [
    {
      "id": "file123",
      "name": "documento.pdf",
      "description": "Contrato de servicios...",
      "type": "pdf",
      "path": "2005/documento.pdf",
      "metadata": {...}
    }
  ],
  "manifest": {
    "folder_id": "...",
    "processed_at": "...",
    "total_files": 5,
    "files": [...]
  }
}
```

### Endpoint: `POST /summarize`

Endpoint gen√©rico para procesar documentos individuales desde diferentes fuentes. √ötil para procesar archivos espec√≠ficos.

#### Modo 1: Google Drive (recomendado)

**Ejemplo A: Procesar archivo espec√≠fico por `file_id` directo**
```bash
curl -X POST "http://localhost:8567/summarize" \
  -H "Content-Type: application/json" \
  -d '{
    "documents": [{
      "id": "mi-doc-especifico",
      "type": "pdf",
      "source": {
        "mode": "gdrive",
        "file_id": "1meKomn0YlFBHa8HFt0XjDkHApiM7XJr5",
        "language": "es"
      }
    }]
  }'
```

**Ejemplo B: Procesar archivo por nombre dentro de una carpeta con par√°metros personalizados**

```bash
curl -X POST "http://localhost:8567/summarize" \
  -H "Content-Type: application/json" \
  -d '{
    "documents": [
      {
        "id": "2-2005",
        "type": "pdf",
        "source": {
          "mode": "gdrive",
          "folder_id": "1C4X9NnTiwFGz3We2D4j-VpINHgCVjV4Y",
          "file_name": "2-2005.pdf",
          "language": "es",
          "initial_pages": 2,
          "final_pages": 2,
          "max_tokens": 500,
          "temperature": 0.2,
          "top_p": 0.9
        }
      }
    ]
  }'
```

#### Modo 2: Ruta Local
```bash
curl -X POST "http://localhost:8567/summarize" \
  -H "Content-Type: application/json" \
  -d '{
    "documents": [
      {
        "id": "doc1",
      "type": "pdf",
      "source": {
        "mode": "local",
        "path": "/data/sample.pdf",
        "language": "es",
        "initial_pages": 2,
        "final_pages": 2
      }
    }
  ]
}
```

#### Modo 3: Carga Directa (Web UI)
```bash
curl -X POST "http://localhost:8567/upload" \
  -H "accept: text/html" \
  -H "Content-Type: multipart/form-data" \
  -F "files=@/path/to/invoice.pdf"
```

## üíª Uso del CLI

El CLI permite procesar documentos desde la l√≠nea de comandos. Soporta dos modos principales: **local** (archivos del sistema) y **gdrive** (Google Drive).

> [!IMPORTANT]
> **Ejecuci√≥n del CLI**: Los comandos CLI deben ejecutarse **dentro del contenedor Docker** o en un entorno virtual con las dependencias instaladas.

### Opci√≥n 1: Ejecutar dentro del contenedor (Recomendado)
```bash
# Acceder al contenedor
docker exec -it summarizer bash

# Dentro del contenedor, ejecutar comandos CLI
python3 -m app.cli gdrive 1C4X9NnTiwFGz3We2D4j-VpINHgCVjV4Y --language es --output /data/manifest.json
```

> [!WARNING]
> **Limitaci√≥n de archivos**: Al ejecutar en Docker, solo se tiene acceso a los archivos dentro del contenedor. Por defecto, se mapea la carpeta `./data` del host a `/data` en el contenedor. **Ha de asegurarse la copia de los archivos que se quieran procesar a la carpeta `data/` de este proyecto** antes de ejecutar el comando local desde el contenedor.

### Opci√≥n 2: Ejecutar en entorno virtual local
```bash
# Crear y activar entorno virtual
python3 -m venv venv
source venv/bin/activate # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt

# Ejecutar comandos CLI
python3 -m app.cli gdrive 1C4X9NnTiwFGz3We2D4j-VpINHgCVjV4Y --language es --output manifest.json
```

> [!NOTE]
> **Acceso completo**: En este modo (o instalando los requisitos sin entorno virtual), el CLI tiene acceso a **todos los archivos de tu sistema host**, ya que se ejecuta directamente en el entorno sin las restricciones de aislamiento de Docker.

### Procesar carpeta local

```bash
# Dentro del contenedor
docker exec -it summarizer bash

# Procesar archivo PDF √∫nico (desde dentro del contenedor)
root@14fc8e42761c:/app# python3 -m app.cli local '/data/3-2005.pdf'

# Con configuraci√≥n por defecto (2 p√°ginas iniciales, 2 finales)
python3 -m app.cli local /ruta/a/carpeta --language es --output resultados.json

# Con configuraci√≥n personalizada
(venv) alejandro@alejandro-XPS-14-9440:/opt/summarizer$ python3 -m app.cli local '/home/alejandro/Documentos/REGISTRO/Ejemplos Registro/2005_reduced.zip' \
  --language es \
  --initial-pages 3 \
  --final-pages 4 \
  --max-tokens 500 \
  --temperature 0.3 \
  --output /data/resultados.json
```

### Procesar carpeta de Google Drive

```bash
# Dentro del contenedor
docker exec -it summarizer bash

# Por ID de carpeta con configuraci√≥n por defecto
python3 -m app.cli gdrive 1C4X9NnTiwFGz3We2D4j-VpINHgCVjV4Y --language es --output resultados.json

# Por URL completa con p√°ginas personalizadas
python3 -m app.cli gdrive "https://drive.google.com/drive/u/0/folders/1C4X9NnTiwFGz3We2D4j-VpINHgCVjV4Y" --language es --initial-pages 3 --final-pages 3

# Con par√°metros de modelo personalizados
python3 -m app.cli gdrive 1C4X9NnTiwFGz3We2D4j-VpINHgCVjV4Y \
  --max-tokens 400 \
  --temperature 0.2 \
  --top-p 0.8 \
  --output custom_gdrive.json
```

### Ver ayuda del CLI
```bash
# Dentro del contenedor
docker exec -it summarizer bash

# Ayuda general
python3 -m app.cli --help

# Ayuda del comando local
python3 -m app.cli local --help

# Ayuda del comando gdrive
python3 -m app.cli gdrive --help
```

### Variables de Entorno

| Variable | Descripci√≥n | Default | Requerido |
| :--- | :--- | :--- | :--- |
| `MODEL_API_URL` | URL de Chat Completions del LLM | `http://192.168.4.32:4000/v1/chat/completions` | S√≠ |
| `MODEL_API_TOKEN` | Token de autenticaci√≥n para la API del modelo (opcional) | `None` | No |
| `VLLM_MODEL` | Modelo multimodal para procesamiento de PDFs (v√≠a `VLLMService`) | `mistralai/Mistral-Small-3.2-24B-Instruct-2506` | S√≠ |
| `LLM_MODEL` | Modelo de texto para macro-res√∫menes de ZIP (v√≠a `LLMService`) | `Qwen/Qwen3-32B` | S√≠ |
| `USE_VLLM_FOR_ALL` | Si es `true`, ignora `LLM_MODEL` y usa `VLLM_MODEL` para todo. | `false` | No |
| `GOOGLE_DRIVE_ENABLED` | Habilitar servicio de Google Drive | `true` | S√≠ |
| `GOOGLE_DRIVE_CREDENTIALS` | Ruta al archivo de credenciales JSON | `./secrets/google-credentials.json` | S√≠ |
| `API_PORT` | Puerto en el que se expone la API | `8567` | No |

### Par√°metros del Modelo (Opcionales en el POST)

| Par√°metro | Descripci√≥n | Default | Rango |
|-----------|-------------|---------|-------|
| `max_tokens` | **Longitud m√°xima** de la descripci√≥n generada por el LLM. | `512` | 10-4096 |
| `temperature` | **Creatividad/Aleatoriedad**: Valores bajos (0.1) dan respuestas coherentes y precisas; valores altos (0.8+) dan respuestas m√°s variadas y creativas. | `0.1` | 0.0-2.0 |
| `top_p` | **Muestreo Nucleus**: Controla la diversidad de palabras seleccionadas por el modelo bas√°ndose en la probabilidad acumulada. | `0.9` | 0.0-1.0 |
| `initial_pages` | N√∫mero de **p√°ginas al principio** del PDF que el modelo "leer√°" para entender el contexto inicial. | `2` | >= 0 |
| `final_pages` | N√∫mero de **p√°ginas al final** del PDF (anexos, firmas, conclusiones) que el modelo analizar√°. | `2` | >= 0 |

## üß† Detalles de Implementaci√≥n L√≥gica

### Estrategia de Resumen de PDF

En lugar de hacer OCR ciego de todo el documento, usamos una **Estrategia Multimodal**:

1.  **Renderizar**: Convierte las **primeras N** y **√∫ltimas M** p√°ginas del PDF a im√°genes de alta resoluci√≥n (por defecto: 2 iniciales y 2 finales, configurable).
2.  **Prompt & Structured Output**:
    - **System Prompt**: *"You are a helpful assistant..."*
    - **JSON Schema**: Se impone un esquema estricto (`{"description": "string"}`) usando el modo **JSON Mode/Structured Outputs** del LLM para garantizar respuestas parseables.
3.  **Descripci√≥n**: La salida es una descripci√≥n densa en texto plano, parseada desde el JSON.

### Observabilidad
El servicio implementa logging estructurado a `stdout`, permitiendo trazar:
- Recepci√≥n de archivos.
- Conversi√≥n PDF -> Im√°genes.
- Payload al LLM (configuraci√≥n de tokens/schema).
- Respuesta raw del LLM y √©xito del parseo.

**Configuraci√≥n de p√°ginas**: El n√∫mero de p√°ginas iniciales y finales a procesar es configurable mediante los par√°metros `initial_pages` y `final_pages` (por defecto: 2 cada uno). Esto permite optimizar el procesamiento seg√∫n el tipo de documento:
- Documentos cortos: usar menos p√°ginas
- Documentos largos: usar m√°s p√°ginas iniciales/finales para capturar mejor el contexto

### Manejo de ZIP

1. Descomprimir a un directorio temporal.
2. Iterar a trav√©s de todos los archivos PDF encontrados recursivamente.
3. Resumir cada PDF individualmente usando la misma estrategia multimodal.
4. Agregador: Crear un resumen final describiendo la *colecci√≥n* (ej: "Un conjunto de 5 facturas correspondientes a Q3 2024").

### Extracci√≥n de ID de Carpeta de Google Drive

El servicio puede extraer autom√°ticamente el ID de carpeta de URLs de Google Drive:
- URL completa: `https://drive.google.com/drive/u/0/folders/16JqSg7BuAE_o1wkFM4q4QUWXMgLRcjFh`
- ID directo: `16JqSg7BuAE_o1wkFM4q4QUWXMgLRcjFh`

Ambos formatos son aceptados.

## Modelos disponibles

| Modelo                                            | Tipo / Descripci√≥n                                                        |
| ------------------------------------------------- | ---------------------------------------------------------------------------------- |
| **BAAI/bge-reranker-v2-m3**                       | Modelo **Reranker** (para ordenar resultados, b√∫squedas)                           |
| **cpatonn/Qwen3-VL-32B-Instruct-AWQ-4bit**        | Modelo multimodal **VL** (Vision + Language), Instruct, 32B par√°metros, 4bit quant |
| **input_inspector**                               | Herramienta o modelo para inspecci√≥n/diagn√≥stico, no un LLM t√≠pico                 |
| **meta-llama/Llama-3-3.3-70B-Instruct**           | Modelo **Llama 3**, 70B par√°metros, instructivo (LLM solo texto)                   |
| **mistralai/Magistral-Small-2509**                | Modelo VLLM peque√±o
| **mistralai/Ministral-3-14B-Instruct-2512**       | Modelo VLLM peque√±o, 14B par√°metros
| **mistralai/Mistral-Small-3.2-24B-Instruct-2506** | Modelo VLLM, 24B par√°metros
| **openai/gpt-oss-120b**                           | GPT open source, 120B par√°metros, solo texto                                       |
| **openai/whisper-large-v3-turbo**                 | Modelo de reconocimiento de voz (ASR), no texto/imagen                             |
| **Qwen/Qwen3-32B**                                | LLM texto solo, 32B par√°metros                                                     |
| **Qwen/Qwen3-32B-AWQ**                            | Igual que anterior pero con cuantizaci√≥n AWQ para optimizaci√≥n                     |
| **Qwen/Qwen3-4B**                                 | LLM texto solo, 4B par√°metros                                                      |
| **Qwen/Qwen3-8B-AWQ**                             | LLM texto solo, 8B par√°metros, AWQ cuantizado                                      |
| **Qwen/Qwen3-Embedding-4B**                       | Modelo para generar embeddings vectoriales, no generaci√≥n texto                    |
| **Qwen/Qwen3-Reranker-8B**                        | Modelo reranker, para clasificaci√≥n/ordenaci√≥n                                     |
| **Qwen/Qwen3-VL-235B-A22B-Instruct**              | Multimodal VL, muy grande (235B+), instructivo                                     |
| **Qwen/Qwen3-VL-32B-Thinking**                    | Multimodal VL 32B par√°metros |
| **SmolPiper**                                     | -                        |
| **Snowflake/snowflake-arctic-embed-l-v2.0**       | Modelo embedding para vectores, tipo b√∫squeda o recomendaci√≥n                      |